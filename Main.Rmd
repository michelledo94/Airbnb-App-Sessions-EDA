---
title: "Airbnb user insight EDA and booking demand prediction"
---
The Airbnb project from Kaggle includes 2 major datasets on new users' insights and app session whose details are as follows: 

users_train.csv -
id: user id,
date_account_created: the date of account creation,
timestamp_first_active: timestamp of the first activity, note that it can be earlier than date_account_created or date_first_booking because a user can search before signing up,
date_first_booking: date of first booking,
gender,
age,
signup_method,
signup_flow: the page a user came to sign up from,
language: international language preference,
affiliate_channel: what kind of paid marketing,
affiliate_provider: where the marketing is e.g. google, craigslist, other,
first_affiliate_tracked: whats the first marketing the user interacted with before the signing up,
signup_app,
first_device_type,
first_browser and
country_destination: this is the target variable you are to predict

sessions.csv - web sessions log for users -
user_id: to be joined with the column 'id' in users table,
action,
action_type,
action_detail,
device_type,
secs_elapsed.

Load the dataset:
  
```{r message=FALSE, warning=FALSE}
library(dplyr)
library(ggplot2)
library(ggcorrplot)
library(caret)
library(plyr)
```


```{r include=FALSE}
full = read.csv("E:/MSBA/7 Predictive Analytics/Project/Datasets/train_users.csv")
sessions=read.csv("E:/MSBA/7 Predictive Analytics/Project/Datasets/sessions.csv")
```


```{r}
head(full)
head(sessions)
```


**Data preprocessing**
Check the pattern of missing data:

```{r}
library(plyr)
# Unique values per column
lapply(full, function(x) length(unique(x))) 
```



```{r}
#Check for Missing values
library(tidyr)
missing_values = full %>% summarize_all(funs(sum(is.na(.))/n()))
missing_values = gather(missing_values, key="feature", value="missing_pct")
missing_values %>% 
  ggplot(aes(x=reorder(feature,-missing_pct),y=missing_pct))+
  geom_bar(stat="identity",fill="red")+
  coord_flip()+theme_bw()
```

The result shows that in the training set only 60% of the observations are complete with 45% missing in gender, 42% missing in age. Since the purpose of the analysis is to identify differences in user behavior among different age and gender groups, we can't afford to remove age and gender or impute a categorical variable like gender. If a better dataset is not available, my solution is to remove incomplete observations.  


```{r}
newdata=na.omit(full) #no dummification
newdata=newdata %>%
  filter(age < 100 & age>18) %>%
  droplevels() #remove people over 100 years old 
```


Create a new variable "agegroup", selecting age brackets based on a cluster analysis of 5 major groups of users.

```{r}
library(psych)
newdata$agegroup[newdata$age<26]="Below 26"
newdata$agegroup[newdata$age<36 & newdata$age>25]="26 to 35"
newdata$agegroup[newdata$age<46 & newdata$age>35]="36 to 45"
newdata$agegroup[newdata$age<56 & newdata$age>45]="46 to 55"
newdata$agegroup[newdata$age>55]="Over 56"
newdata$agegroup=factor(newdata$agegroup, levels = c("Below 26", "26 to 35", "36 to 45", "46 to 55", "Over 56"))
```



Combine tables to join the sessions dataset, removing observations that are not included in the full dataset. 

```{r}
library(plyr)
join=join(sessions, newdata, by="id", type= "inner", match="all")
join=na.omit(join)
newsessions=select(join, 1:6)
```

** Exploratory Data Analysis **

It should be noted that the dataset is made up mostly of categorical variables, which makes it hard to create correlation matrix, box plots or scatter plots. Some notable trends are shown as follows:

```{r}
m = subset(newdata$gender, newdata$book==1)
barplot(prop.table(table(newdata$gender)), main = "Distribution of users who booked by gender", col="tomato2")
```

```{r}
ggplot(newdata, aes(x=country_destination, fill=gender)) +
  geom_bar(position="dodge")+
  labs(title="Country destination broken down by gender")
  
```

* Note: NDF is the people who don't book homestays at all. 
Because the dataset is all about US users, America is the most popoular spot. Other than that, France and Spain are the most preferred ones.  


```{r}
ggplot(newdata,
       aes(x=reorder(first_device_type, first_device_type,
                     function(x)-length(x)))) +
  geom_bar()+
  labs(title = "First device type frequency") +
  xlab("Device")+
  theme(axis.text.x = element_text(angle = 35, hjust = 1))
```


```{r}
ggplot(newdata,
       aes(x=reorder(affiliate_channel, affiliate_channel,
                     function(x)-length(x)))) +
  geom_bar()+
  labs(title = "Affiliate channel") +
  xlab("Channel")+
  theme(axis.text.x = element_text(angle = 35, hjust = 1))
```



```{r}
ggplot(newdata,
       aes(x=reorder(affiliate_provider, affiliate_provider,
                     function(x)-length(x)))) +
  geom_bar()+
  labs(title = "Affiliate providers") +
  xlab("Provider")+
  theme(axis.text.x = element_text(angle = 35, hjust = 1))
```


```{r}
m = subset(newdata$age, newdata$book==1)
n = subset(newdata$age, newdata$book==0)
plot(density(m), col="red", main="Age distribution", xlab="Age - Red line: Users who booked, Blue line: Users who dropped")
lines(density(n), col="blue")
```

It can be seen that the users that booked are mostly aged 25 to 35. 

```{r}
ggplot(newdata, aes(x=agegroup, fill=affiliate_channel))+
  geom_bar(position="fill")+
  ylab("proportion")
```


```{r}
ggplot(newdata,
       aes(x=reorder(first_affiliate_tracked, first_affiliate_tracked,
                     function(x)-length(x)))) +
  geom_bar()+
  labs(title = "First affiliate tracked") +
  xlab("Device")+
  theme(axis.text.x = element_text(angle = 35, hjust = 1))

```


```{r}
ggplot(newdata,
       aes(x=reorder(signup_app, signup_app,
                     function(x)-length(x)))) +
  geom_bar()+
  labs(title = "Signup app") +
  xlab("Device")+
  theme(axis.text.x = element_text(angle = 35, hjust = 1))
```

```{r}
ggplot(newdata,
       aes(x=reorder(signup_method, signup_method,
                     function(x)-length(x)))) +
  geom_bar()+
  labs(title = "Signup method") +
  xlab("Device")
```


```{r}
ggplot(newdata,
       aes(x=reorder(first_browser, first_browser,
                     function(x)-length(x)))) +
  geom_bar()+
  theme(axis.text.x = element_text(angle = 55, hjust = 1))+
  labs(title="First browser")
```

```{r}
ggplot(newdata, aes(x=affiliate_channel, y=age))+
  geom_boxplot()+
  theme(axis.text.x = element_text(angle = 45, hjust = 1))+
  labs(title="Affiliate channel by age")
```

```{r}
ggplot(newdata, aes(x=affiliate_provider, y=age))+
  geom_boxplot()+
  theme(axis.text.x = element_text(angle = 45, hjust = 1))+
  labs(title="Affiliate provider by age")
```


```{r}
ggplot(newdata, aes(x=agegroup, fill=signup_method))+
  geom_bar(position="dodge")
```



```{r}
ggplot(newdata, aes(x=first_affiliate_tracked, fill=gender))+
  geom_bar(position="stack")

```


```{r}
ggplot(newdata, aes(x=agegroup, fill=first_affiliate_tracked))+
  geom_bar(position="stack")
```

Comparing the conversion rate of different affiliate channels:

```{r}
newdata$book=as.factor(newdata$book)
ggplot(newdata, aes(x=affiliate_channel, fill=book))+
  geom_bar(position="stack")+
  theme(axis.text.x = element_text(angle = 30, hjust = 1))
```

It can be seen that content is the worst paid marketing channel. 

Country destination trends broken down by age groups:

```{r}
ggplot(newdata, aes(x=country_destination, fill=agegroup))+
  geom_bar(position="stack")
```


See the relationship between conversion rate and action types

```{r}
join=join %>%
  filter(action_type!="" & action_type!="-unknown-") %>%
  droplevels()
join$book=as.factor(join$book)
ggplot(join, aes(x=action_type, fill=book), las=2)+
  geom_bar(position="stack")+
  theme(axis.text.x = element_text(angle = 35, hjust = 1))
```


```{r}
summary(join$secs_elapsed)
```

There are so many outliers that it's hard to plot a good boxplot. Let's transform the second data into minutes to reduce the sparseness of the data. 


```{r}
join=mutate(join, mins_elapsed=secs_elapsed/60)
plot(join$age, join$mins_elapsed)
```


```{r}
ggplot(join, aes(x=action_type, y=secs_elapsed))+
  geom_boxplot()
```

```{r}
ggplot(join, aes(x=device_type, y = secs_elapsed))+
  geom_boxplot()+
  theme(axis.text.x = element_text(angle = 90, hjust = 1))+
  labs(title="Seconds elapsed broken down by device type")
```


```{r}
ggplot(join,
       aes(x=reorder(action, action,
                     function(x)-length(x)))) + 
  geom_bar()+
  labs(title = "Action on app") +
  xlab("Action")+
  theme(text = element_text(size=8),
        axis.text.x = element_text(angle = 90, hjust = 1))
        
```


**Logistic Regression**

Dummify categorical variables: 

```{r}
categories = full[,c(5,7,9:16)] #pick out categorical variables needed to be dummified
categories = lapply(categories, as.factor)
dummify=dummyVars(~.,data=categories, sep=".", fullRank=TRUE) #dummify categorical variabels, drop one level of each variable
new_categories=as.data.frame(predict(dummify, newdata=categories))
```


```{r}
train1=mutate(age=full$age,new_categories, book=full$book)
nrow(train1) #number of obs
```

```{r}
train1=na.omit(train1)
```


Split data for logistic regression

```{r}
split=round(nrow(train1)*.8)
train=train1[1:split,]
test=train1[(split+1):nrow(train1),]
```


Logistic regression algorithm would not converge if we include all variables into our models. To make it easier to interpret results and compare variables, I try models with different groups of related variables: 
Model 1: book ~ age + gender + signup_method 

```{r}
train3=train[,c(1:4, 132, 133)] #age+gender+signup_method
model1 = glm(book~., family="binomial", data=train3)
summary(model1)
```

Based on p-value, keep all except signup_method.google. 

Model 2: book ~ affiliate_channel + affiliate_provider + signup_app

```{r}
train4=train[,c(29:62, 133)] #affiliate_channel, affiliate_provider, signup app
model2=glm(book~., family="binomial", data=train4)
summary(model2)
```

Keep only affiliate_channel.content and affiliate_channel.direct, affiliate_channel.seo, first_affiliate_tracked.linked, first_affiliate_tracked.omg, first_affiliate_tracked.product, first_affiliate_tracked-other, signup_app.iOS, signup_app.Web

Model 3: book ~ first_browser + first_device_type 

```{r}
train5 = train[,c(63:120, 133)] #first_browser and first_device_type
model3=glm(book~., family="binomial", data=train5)
summary(model3)
```

Keep first_device_type.iPad, first_device_type.iPhone, first_browser.Chrome Mobile, first_browswer.Mobile Safari. 

Final model - combine all selected variables: 

```{r}
train_final = mutate(train[,c(1:3, 132, 133, 29, 30,35,53,56:58,60,62, 65, 66, 78,98)]) #combine selected variables

model = glm(book~., family="binomial", data=train_final)
models=step(model, direction="backward") # Run stepwise regression with backward elimination
summary(models)
```

Predict on the test set

```{r}
test_final=mutate(test[,c(1:3, 132, 133, 29, 30,35,53,56:58,60,62, 65, 66, 78,98)])
prob = predict(models, newdata=test_final, type = "response")
```

Check AUC:

```{r}
library(ROCR)
ROCRPred = prediction(prob, test$book)
auc = round(as.numeric(performance(ROCRPred, "auc")@y.values),2)
auc
```

The low AUC score indicates that variables included in the dataset are not good predictors of whether or not a new user proceed to booking after visiting Airbnb mobile/web apps. There might be a lot of lurking variables that we may have to figure out. 

See variable significance:

```{r}
barplot(sort(abs(models$coefficients[-1]), decreasing=TRUE), col="steelblue", las=3, cex.names = 0.6, main="Variable significance")
```

Let's see how accurate the the final model could achieve: 

Class distribution of the training set: 

```{r}
barplot(prop.table(table(train$book)), main = "Train book", width=.2, xlim = c(0,1), col="steelblue")
```


```{r}
quantile(prob, prob = seq(0, 1, length = 11), type = 5, na.rm = TRUE)
```

Assuming that there is a similar pattern of probability distribution on the test set, I choose a cutoff at 0.6 - near the 50th percentile.

Check accuracy 

```{r}
class=ifelse(prob>0.6,1,0)
c_accuracy=function(actuals,classifications){
  df=data.frame(actuals,classifications);
  
  
  tp=nrow(df[df$classifications==1 & df$actuals==1,]);        
  fp=nrow(df[df$classifications==1 & df$actuals==0,]);
  fn=nrow(df[df$classifications==0 & df$actuals==1,]);
  tn=nrow(df[df$classifications==0 & df$actuals==0,]); 
  
  
  recall=tp/(tp+fn)
  precision=tp/(tp+fp)
  accuracy=(tp+tn)/(tp+fn+fp+tn)
  tpr=recall
  fpr=fp/(fp+tn)
  fmeasure=2*precision*recall/(precision+recall)
  scores=c(recall,precision,accuracy,tpr,fpr,fmeasure,tp,tn,fp,fn)
  names(scores)=c("recall","precision","accuracy","tpr","fpr","fmeasure","tp","tn","fp","fn")
  
  #print(scores)
  return(scores);
}
c_accuracy(test_final$book,class)
```

The final model and accuracy rate could be improved if we have more information on users, i.e. acquired from their Facebook profile, as most of them signed up using Facebook. 

